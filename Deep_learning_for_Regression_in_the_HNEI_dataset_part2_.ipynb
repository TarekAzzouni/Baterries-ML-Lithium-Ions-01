{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning for Regression in the HNEI dataset part2 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSIhdqjDV3OF7nSqqNl4xi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarekAzzouni/Baterries-ML-Lithium-Ions-01/blob/main/Deep_learning_for_Regression_in_the_HNEI_dataset_part2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dIK5D6OnJkw"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from scipy.stats import norm, boxcox\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import requests\n",
        "import os\n",
        "\n",
        "from warnings import simplefilter\n",
        "import warnings\n",
        "# ignore all warnings\n",
        "simplefilter(action='ignore')\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj07k0tAnmia"
      },
      "source": [
        "url=\"https://www.batteryarchive.org/data/HNEI_18650_NMC_LCO_25C_0-100_0.5-1.5C_a_timeseries.csv\"\n",
        "s = requests.get(url).content\n",
        "data = pd.read_csv(io.StringIO(s.decode('utf-8')))"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "nftDhI71nqjY",
        "outputId": "d4695d45-b669-4b71-e16a-60fd09058c57"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_Time</th>\n",
              "      <th>Test_Time (s)</th>\n",
              "      <th>Cycle_Index</th>\n",
              "      <th>Current (A)</th>\n",
              "      <th>Voltage (V)</th>\n",
              "      <th>Charge_Capacity (Ah)</th>\n",
              "      <th>Discharge_Capacity (Ah)</th>\n",
              "      <th>Charge_Energy (Wh)</th>\n",
              "      <th>Discharge_Energy (Wh)</th>\n",
              "      <th>Environment_Temperature (C)</th>\n",
              "      <th>Cell_Temperature (C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-05-22 11:46:56</td>\n",
              "      <td>30.014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-05-22 11:47:26</td>\n",
              "      <td>59.999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-05-22 11:47:33</td>\n",
              "      <td>67.294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-05-22 11:47:41</td>\n",
              "      <td>74.303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-05-22 11:47:48</td>\n",
              "      <td>81.310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>3.659</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date_Time  ...  Cell_Temperature (C)\n",
              "0  2013-05-22 11:46:56  ...                   NaN\n",
              "1  2013-05-22 11:47:26  ...                   NaN\n",
              "2  2013-05-22 11:47:33  ...                   NaN\n",
              "3  2013-05-22 11:47:41  ...                   NaN\n",
              "4  2013-05-22 11:47:48  ...                   NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "E0RHHIo_nrj_",
        "outputId": "ab8ec70a-a705-4171-cb0d-c297dd6eef0f"
      },
      "source": [
        "train = data[data['Cycle_Index'] == 1 ]\n",
        "train"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_Time</th>\n",
              "      <th>Test_Time (s)</th>\n",
              "      <th>Cycle_Index</th>\n",
              "      <th>Current (A)</th>\n",
              "      <th>Voltage (V)</th>\n",
              "      <th>Charge_Capacity (Ah)</th>\n",
              "      <th>Discharge_Capacity (Ah)</th>\n",
              "      <th>Charge_Energy (Wh)</th>\n",
              "      <th>Discharge_Energy (Wh)</th>\n",
              "      <th>Environment_Temperature (C)</th>\n",
              "      <th>Cell_Temperature (C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-05-22 11:46:56</td>\n",
              "      <td>30.014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-05-22 11:47:26</td>\n",
              "      <td>59.999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-05-22 11:47:33</td>\n",
              "      <td>67.294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.670</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-05-22 11:47:41</td>\n",
              "      <td>74.303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.664</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-05-22 11:47:48</td>\n",
              "      <td>81.310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>3.659</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>2013-05-22 15:49:05</td>\n",
              "      <td>14558.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.342</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>2013-05-22 15:49:35</td>\n",
              "      <td>14588.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>2013-05-22 15:50:05</td>\n",
              "      <td>14618.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>2013-05-22 15:50:34</td>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>2013-05-22 15:50:35</td>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1956 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Date_Time  ...  Cell_Temperature (C)\n",
              "0     2013-05-22 11:46:56  ...                   NaN\n",
              "1     2013-05-22 11:47:26  ...                   NaN\n",
              "2     2013-05-22 11:47:33  ...                   NaN\n",
              "3     2013-05-22 11:47:41  ...                   NaN\n",
              "4     2013-05-22 11:47:48  ...                   NaN\n",
              "...                   ...  ...                   ...\n",
              "1951  2013-05-22 15:49:05  ...                   NaN\n",
              "1952  2013-05-22 15:49:35  ...                   NaN\n",
              "1953  2013-05-22 15:50:05  ...                   NaN\n",
              "1954  2013-05-22 15:50:34  ...                   NaN\n",
              "1955  2013-05-22 15:50:35  ...                   NaN\n",
              "\n",
              "[1956 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTEgGyLojcA"
      },
      "source": [
        "test = data[data['Cycle_Index'] == 2 ]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-agIuTEpOPW"
      },
      "source": [
        "#rename the charge capacity\n",
        "train1 = train.rename(columns={'Charge_Capacity (Ah)': 'Charge_Capacity'})\n",
        "test1 = test.rename(columns={'Charge_Capacity (Ah)': 'Charge_Capacity'})"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPiIKpzptvef"
      },
      "source": [
        "#train1 = train.drop(['Environment_Temperature (C)','Cell_Temperature (C)','Date_Time','Charge_Capacity'],axis=1)\n",
        "#test1 = test.drop(['Environment_Temperature (C)','Cell_Temperature (C)','Date_Time','Charge_Capacity'],axis=1)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpm8-1MbovrH"
      },
      "source": [
        "def get_data():\n",
        "    \n",
        "    train1 = data[data['Cycle_Index'] == 1 ]\n",
        "    \n",
        "    test1 = data[data['Cycle_Index'] == 2 ]\n",
        "    \n",
        "    return train , test\n",
        "\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJN20myzraZH"
      },
      "source": [
        "Col_target = [\"Charge_Capacity\"]\n",
        "target = train1[Col_target]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TICv9OhfsBuc",
        "outputId": "5c6279a0-1c22-4f82-e20b-9f2a1d8d3db1"
      },
      "source": [
        "train1.columns"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date_Time', 'Test_Time (s)', 'Cycle_Index', 'Current (A)',\n",
              "       'Voltage (V)', 'Charge_Capacity', 'Discharge_Capacity (Ah)',\n",
              "       'Charge_Energy (Wh)', 'Discharge_Energy (Wh)',\n",
              "       'Environment_Temperature (C)', 'Cell_Temperature (C)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H6CruFnpPm_"
      },
      "source": [
        "def get_combined_data():\n",
        "  #reading train data\n",
        "  train1 , test1 = get_data()\n",
        "  #train.drop(['Charge_Capacity'],axis = 1 , inplace = True)\n",
        "\n",
        "  combined = train1.append(test)\n",
        "  combined.reset_index(inplace=True)\n",
        "  combined.drop(['Environment_Temperature (C)', 'Cell_Temperature (C)'], inplace=True, axis=1)\n",
        "  return combined, target\n",
        "\n",
        "#Load train and test data into pandas DataFrames\n",
        "train_data, test_data = get_data()\n",
        "\n",
        "#Combine train and test data to process them together\n",
        "combined, target = get_combined_data()"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ4hZ15oy9zc",
        "outputId": "11fd7881-54fb-4286-8168-8d3d55248298"
      },
      "source": [
        "train1.info()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1956 entries, 0 to 1955\n",
            "Data columns (total 11 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Date_Time                    1956 non-null   object \n",
            " 1   Test_Time (s)                1956 non-null   float64\n",
            " 2   Cycle_Index                  1956 non-null   float64\n",
            " 3   Current (A)                  1956 non-null   float64\n",
            " 4   Voltage (V)                  1956 non-null   float64\n",
            " 5   Charge_Capacity              1956 non-null   float64\n",
            " 6   Discharge_Capacity (Ah)      1956 non-null   float64\n",
            " 7   Charge_Energy (Wh)           1956 non-null   float64\n",
            " 8   Discharge_Energy (Wh)        1956 non-null   float64\n",
            " 9   Environment_Temperature (C)  0 non-null      float64\n",
            " 10  Cell_Temperature (C)         0 non-null      float64\n",
            "dtypes: float64(10), object(1)\n",
            "memory usage: 183.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGyqQI-IzVEW"
      },
      "source": [
        "combined1 = combined.rename(columns={'Charge_Capacity (Ah)': 'Charge_Capacity'})"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zImZPaj8slgp"
      },
      "source": [
        "def get_cols_with_no_nans(df1,col_type):\n",
        "    '''\n",
        "    Arguments :\n",
        "    df : The dataframe to process\n",
        "    col_type : \n",
        "          num : to only get numerical columns with no nans\n",
        "          no_num : to only get nun-numerical columns with no nans\n",
        "          all : to get any columns with no nans    \n",
        "    '''\n",
        "    if (col_type == 'num'):\n",
        "        predictors = df1.select_dtypes(exclude=['object'])\n",
        "    elif (col_type == 'no_num'):\n",
        "        predictors = df1.select_dtypes(include=['object'])\n",
        "    elif (col_type == 'all'):\n",
        "        predictors = df1\n",
        "    else :\n",
        "        print('Error : choose a type (num, no_num, all)')\n",
        "        return 0\n",
        "    cols_with_no_nans = []\n",
        "    for col in predictors.columns:\n",
        "        if not df1[col].isnull().any():\n",
        "            cols_with_no_nans.append(col)\n",
        "    return cols_with_no_nans"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_GRCn_Isqdq"
      },
      "source": [
        "num_cols = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols = get_cols_with_no_nans(combined , 'no_num')"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCgvle8sss1S",
        "outputId": "1c766b16-4355-454d-88cd-88f4d9d980bf"
      },
      "source": [
        "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 9\n",
            "Number of nun-numerical columns with no nan values : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izNJlhdgvtBG"
      },
      "source": [
        "***One Hot Encode The Categorical Features :***\n",
        "\n",
        "We will encode the categorical features using one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF6W9tJ9vqOq"
      },
      "source": [
        "def oneHotEncode(df1,colNames):\n",
        "    for col in colNames:\n",
        "        if( df1[col].dtype == np.dtype('object')):\n",
        "            dummies = pd.get_dummies(df1[col],prefix=col)\n",
        "            df1 = pd.concat([df1,dummies],axis=1)\n",
        "\n",
        "            #drop the encoded column\n",
        "            df1.drop([col],axis = 1 , inplace=True)\n",
        "    return df1"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwwNWDrmv3rT",
        "outputId": "eedefab6-0ac9-4b5b-fcee-da216eb77571"
      },
      "source": [
        "print('There were {} columns before encoding categorical features'.format(combined1.shape[1]))\n",
        "combined1 = oneHotEncode(combined1, cat_cols)\n",
        "print('There are {} columns after encoding categorical features'.format(combined1.shape[1]))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were 10 columns before encoding categorical features\n",
            "There are 4567 columns after encoding categorical features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxhl4zOv73i"
      },
      "source": [
        "Now, split back combined dataFrame to training data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqjnlzWLv8nN"
      },
      "source": [
        "def split_combined():\n",
        "    global combined1\n",
        "    train1 = combined1[:1460]\n",
        "    test1 = combined1[1460:]\n",
        "\n",
        "    return train1 , test1 "
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHZOKq09wAF6"
      },
      "source": [
        "train1, test1 = split_combined()"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZJup4fQwEIp"
      },
      "source": [
        "# Second : Make the Deep Neural Network\n",
        "\n",
        "\n",
        "*   Define a sequential model\n",
        "*   Add some dense layers\n",
        "*   Use 'relu' as the activation function in the hidden layers\n",
        "*   Use a 'normal' initializer as the kernal_intializer\n",
        "\n",
        "```\n",
        " Initializers define the way to set the initial random weights of Keras layers.\n",
        "```\n",
        "*   We will use mean_absolute_error as a loss function\n",
        "*   Define the output layer with only one node\n",
        "*   Use 'linear 'as the activation function for the output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzeYnOEiwlIE"
      },
      "source": [
        "NN_model = Sequential()"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0am5f-ExNvB"
      },
      "source": [
        "**The input Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6uA15abxQeV"
      },
      "source": [
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train1.shape[1], activation='relu'))"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD-iAszBxSSc"
      },
      "source": [
        "**The Hidden Layers**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78s9O0_LxUmL"
      },
      "source": [
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgubWleQxbOW"
      },
      "source": [
        "**The output layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Ukeeirxffa"
      },
      "source": [
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLFK8K6Kxjwu"
      },
      "source": [
        "**Compile the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K37ClO-rxlWS",
        "outputId": "30b3da01-ef53-4e03-aafe-264b4882cf28"
      },
      "source": [
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 128)               584704    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 815,361\n",
            "Trainable params: 815,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJ39A_Rx2Hz"
      },
      "source": [
        "## Third : Train the model :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGR3u19Tx1hF",
        "outputId": "d15c76db-8354-45ff-c8f9-bb9502efcf10"
      },
      "source": [
        "history = NN_model.fit(train1, target, epochs=200, batch_size=30, validation_split = 0.2)#, metrics=['accuracy']) #callbacks=callbacks_list)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 2s 22ms/step - loss: 7.7238 - accuracy: 0.1981 - val_loss: 1.2888 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.4769 - accuracy: 0.2836 - val_loss: 0.4071 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.3140 - accuracy: 0.3083 - val_loss: 0.6714 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2895 - accuracy: 0.3177 - val_loss: 1.2091 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.2760 - accuracy: 0.3314 - val_loss: 0.8895 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2353 - accuracy: 0.3130 - val_loss: 0.7237 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 0.3128 - val_loss: 0.4565 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2057 - accuracy: 0.3231 - val_loss: 0.4726 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1993 - accuracy: 0.3030 - val_loss: 0.3936 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1990 - accuracy: 0.3218 - val_loss: 0.8224 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1941 - accuracy: 0.3160 - val_loss: 0.4829 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2170 - accuracy: 0.3470 - val_loss: 0.2128 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1782 - accuracy: 0.3073 - val_loss: 0.5018 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.3032 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1466 - accuracy: 0.3390 - val_loss: 0.7414 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1469 - accuracy: 0.3133 - val_loss: 0.1201 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.3108 - val_loss: 0.0666 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1677 - accuracy: 0.3190 - val_loss: 0.2649 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2415 - accuracy: 0.3248 - val_loss: 0.7303 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.2723 - accuracy: 0.3176 - val_loss: 0.1015 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1312 - accuracy: 0.3313 - val_loss: 0.0415 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1143 - accuracy: 0.3166 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1117 - accuracy: 0.3243 - val_loss: 0.0647 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1222 - accuracy: 0.3312 - val_loss: 0.4107 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0935 - accuracy: 0.3119 - val_loss: 0.0476 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0713 - accuracy: 0.3155 - val_loss: 0.4005 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 0.3250 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.1126 - accuracy: 0.3421 - val_loss: 0.2342 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0951 - accuracy: 0.3154 - val_loss: 0.6118 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.3214 - val_loss: 0.1249 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.3210 - val_loss: 0.0826 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0916 - accuracy: 0.3077 - val_loss: 0.0257 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0758 - accuracy: 0.3155 - val_loss: 0.2333 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0640 - accuracy: 0.3055 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.3140 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0470 - accuracy: 0.3164 - val_loss: 0.0840 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.3164 - val_loss: 0.2949 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.3305 - val_loss: 0.2611 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1051 - accuracy: 0.3046 - val_loss: 0.1069 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0323 - accuracy: 0.3297 - val_loss: 0.4178 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.3350 - val_loss: 0.0653 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.3231 - val_loss: 0.0995 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.3122 - val_loss: 0.0937 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.3159 - val_loss: 0.0255 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0732 - accuracy: 0.3072 - val_loss: 0.1234 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.3036 - val_loss: 0.1670 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0628 - accuracy: 0.3615 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0864 - accuracy: 0.3508 - val_loss: 0.2477 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.3345 - val_loss: 0.0232 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.3371 - val_loss: 0.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.3186 - val_loss: 0.1187 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.2965 - val_loss: 0.2471 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.3244 - val_loss: 0.2499 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0631 - accuracy: 0.3167 - val_loss: 0.0533 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.3240 - val_loss: 0.3455 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0747 - accuracy: 0.3155 - val_loss: 0.0837 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.3465 - val_loss: 0.1794 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 0.3240 - val_loss: 0.0855 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.3181 - val_loss: 0.1537 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 0.3207 - val_loss: 0.0972 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0332 - accuracy: 0.3165 - val_loss: 0.1224 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.3155 - val_loss: 0.1295 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.3365 - val_loss: 0.0997 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 0.3187 - val_loss: 0.2695 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.3134 - val_loss: 0.1282 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0287 - accuracy: 0.3102 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0712 - accuracy: 0.3172 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.3089 - val_loss: 0.1238 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.3359 - val_loss: 0.0826 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0344 - accuracy: 0.3273 - val_loss: 0.0727 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.3302 - val_loss: 0.2373 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0516 - accuracy: 0.3233 - val_loss: 0.1295 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0361 - accuracy: 0.3112 - val_loss: 0.0816 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.3187 - val_loss: 0.1447 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.2909 - val_loss: 0.0541 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.3320 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0383 - accuracy: 0.3405 - val_loss: 0.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0443 - accuracy: 0.3015 - val_loss: 0.0387 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.3074 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0438 - accuracy: 0.3324 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.3403 - val_loss: 0.0394 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.3063 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.3285 - val_loss: 0.2106 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.3269 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.3278 - val_loss: 0.1085 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.3375 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.3156 - val_loss: 0.0852 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.3251 - val_loss: 0.0623 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.3172 - val_loss: 0.0376 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.3164 - val_loss: 0.0816 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 0.3208 - val_loss: 0.0876 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0426 - accuracy: 0.3397 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.3357 - val_loss: 0.0311 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.3292 - val_loss: 0.0535 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.3196 - val_loss: 0.0419 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.3339 - val_loss: 0.1244 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0413 - accuracy: 0.3371 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.3335 - val_loss: 0.0961 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.3226 - val_loss: 0.0550 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0393 - accuracy: 0.3396 - val_loss: 0.0925 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.3157 - val_loss: 0.0747 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0466 - accuracy: 0.3316 - val_loss: 0.1196 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.3220 - val_loss: 0.0658 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.3231 - val_loss: 0.0315 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.3317 - val_loss: 0.0396 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.3296 - val_loss: 0.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0492 - accuracy: 0.2954 - val_loss: 0.0995 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.3322 - val_loss: 0.1635 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0508 - accuracy: 0.3311 - val_loss: 0.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 0.3172 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.3001 - val_loss: 0.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0332 - accuracy: 0.3245 - val_loss: 0.2496 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.3016 - val_loss: 0.0581 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0286 - accuracy: 0.3190 - val_loss: 0.0234 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.3095 - val_loss: 0.0267 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.3099 - val_loss: 0.1945 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.3134 - val_loss: 0.0837 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.3175 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0537 - accuracy: 0.3345 - val_loss: 0.0772 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.3614 - val_loss: 0.0440 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.3186 - val_loss: 0.2078 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.3104 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.3236 - val_loss: 0.0559 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.3360 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.3278 - val_loss: 0.1086 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.3198 - val_loss: 0.2078 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0417 - accuracy: 0.3362 - val_loss: 0.0562 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.3475 - val_loss: 0.0393 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.3235 - val_loss: 0.1218 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.3024 - val_loss: 0.0865 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.3223 - val_loss: 0.0549 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.3058 - val_loss: 0.0197 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.3280 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.2948 - val_loss: 0.0638 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.3128 - val_loss: 0.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.3139 - val_loss: 0.0360 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.3203 - val_loss: 0.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.3095 - val_loss: 0.0379 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.3274 - val_loss: 0.0457 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.3317 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.3197 - val_loss: 0.0848 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.3161 - val_loss: 0.0425 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.3060 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.3179 - val_loss: 0.1064 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.3135 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.3211 - val_loss: 0.0513 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.3104 - val_loss: 0.1340 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0328 - accuracy: 0.3026 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.3124 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.3195 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 0.3158 - val_loss: 0.0231 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.3274 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.3008 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.3158 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.3142 - val_loss: 0.0374 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.3360 - val_loss: 0.1922 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 0.3285 - val_loss: 0.0316 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.3094 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.3261 - val_loss: 0.0514 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0341 - accuracy: 0.3221 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.3086 - val_loss: 0.1597 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 0.3222 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.3061 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.3173 - val_loss: 0.0490 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.3166 - val_loss: 0.0808 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.3180 - val_loss: 0.0962 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.3198 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.3147 - val_loss: 0.0361 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.3207 - val_loss: 0.0572 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.3270 - val_loss: 0.1067 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.3274 - val_loss: 0.0635 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.3280 - val_loss: 0.1139 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.3248 - val_loss: 0.1545 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.3261 - val_loss: 0.0528 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.3262 - val_loss: 0.0499 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.3308 - val_loss: 0.0498 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.3091 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.3260 - val_loss: 0.0943 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 0.3098 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.3223 - val_loss: 0.0435 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0105 - accuracy: 0.3527 - val_loss: 0.0320 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.3345 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.3242 - val_loss: 0.0348 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.3212 - val_loss: 0.1105 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.3213 - val_loss: 0.0889 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.3103 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.3302 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.3217 - val_loss: 0.0596 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.3318 - val_loss: 0.0549 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/200\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.3281 - val_loss: 0.0655 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.3008 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.3288 - val_loss: 0.0248 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.3416 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0241 - accuracy: 0.3149 - val_loss: 0.0657 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.3339 - val_loss: 0.1087 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.3046 - val_loss: 0.0264 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.3291 - val_loss: 0.0235 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.3036 - val_loss: 0.0541 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/200\n",
            "39/39 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.2837 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/200\n",
            "39/39 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.3215 - val_loss: 0.1079 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "VuWcqe37BP5b",
        "outputId": "165ba93f-cd5f-49c2-c405-70f883f2dfba"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='target')\n",
        "plt.legend();"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "XT2XhCmIxm4s",
        "outputId": "dee2707e-7adb-4900-b96e-f4a4ec920be2"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend();"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9b8vwEDw2zQ",
        "outputId": "f5ca23cd-1cdb-4048-87c1-47dab4ba2aaf"
      },
      "source": [
        "history1 = NN_model.fit(train1, test1, epochs=150, batch_size=50, validation_split = 0.2)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 3.9522 - accuracy: 0.8581 - val_loss: 5.0808 - val_accuracy: 0.9982\n",
            "Epoch 2/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7595 - accuracy: 0.9983 - val_loss: 5.0759 - val_accuracy: 0.9982\n",
            "Epoch 3/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7553 - accuracy: 0.9983 - val_loss: 5.0801 - val_accuracy: 0.9982\n",
            "Epoch 4/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7551 - accuracy: 0.9983 - val_loss: 5.0791 - val_accuracy: 0.9982\n",
            "Epoch 5/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0757 - val_accuracy: 0.9982\n",
            "Epoch 6/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0764 - val_accuracy: 0.9982\n",
            "Epoch 7/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0794 - val_accuracy: 0.9982\n",
            "Epoch 8/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7548 - accuracy: 0.9983 - val_loss: 5.0779 - val_accuracy: 0.9982\n",
            "Epoch 9/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0793 - val_accuracy: 0.9982\n",
            "Epoch 10/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0759 - val_accuracy: 0.9982\n",
            "Epoch 11/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7557 - accuracy: 0.9983 - val_loss: 5.0754 - val_accuracy: 0.9982\n",
            "Epoch 12/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0744 - val_accuracy: 0.9982\n",
            "Epoch 13/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7552 - accuracy: 0.9983 - val_loss: 5.0760 - val_accuracy: 0.9982\n",
            "Epoch 14/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0772 - val_accuracy: 0.9982\n",
            "Epoch 15/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 16/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0810 - val_accuracy: 0.9982\n",
            "Epoch 17/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7553 - accuracy: 0.9983 - val_loss: 5.0786 - val_accuracy: 0.9982\n",
            "Epoch 18/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7550 - accuracy: 0.9983 - val_loss: 5.0763 - val_accuracy: 0.9982\n",
            "Epoch 19/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7549 - accuracy: 0.9983 - val_loss: 5.0767 - val_accuracy: 0.9982\n",
            "Epoch 20/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 21/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 22/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0775 - val_accuracy: 0.9982\n",
            "Epoch 23/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7557 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 24/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7555 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 25/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7549 - accuracy: 0.9983 - val_loss: 5.0755 - val_accuracy: 0.9982\n",
            "Epoch 26/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7549 - accuracy: 0.9983 - val_loss: 5.0748 - val_accuracy: 0.9982\n",
            "Epoch 27/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 28/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7548 - accuracy: 0.9983 - val_loss: 5.0752 - val_accuracy: 0.9982\n",
            "Epoch 29/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0753 - val_accuracy: 0.9982\n",
            "Epoch 30/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0751 - val_accuracy: 0.9982\n",
            "Epoch 31/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7551 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 32/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0759 - val_accuracy: 0.9982\n",
            "Epoch 33/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 34/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 35/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 36/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0758 - val_accuracy: 0.9982\n",
            "Epoch 37/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0758 - val_accuracy: 0.9982\n",
            "Epoch 38/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0752 - val_accuracy: 0.9982\n",
            "Epoch 39/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0748 - val_accuracy: 0.9982\n",
            "Epoch 40/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0744 - val_accuracy: 0.9982\n",
            "Epoch 41/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 42/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7535 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 43/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 44/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 45/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 46/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0738 - val_accuracy: 0.9982\n",
            "Epoch 47/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7554 - accuracy: 0.9983 - val_loss: 5.0744 - val_accuracy: 0.9982\n",
            "Epoch 48/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 49/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 50/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0755 - val_accuracy: 0.9982\n",
            "Epoch 51/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0749 - val_accuracy: 0.9982\n",
            "Epoch 52/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0752 - val_accuracy: 0.9982\n",
            "Epoch 53/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 54/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0746 - val_accuracy: 0.9982\n",
            "Epoch 55/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 56/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0738 - val_accuracy: 0.9982\n",
            "Epoch 57/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 58/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0762 - val_accuracy: 0.9982\n",
            "Epoch 59/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7553 - accuracy: 0.9983 - val_loss: 5.0760 - val_accuracy: 0.9982\n",
            "Epoch 60/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 61/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0744 - val_accuracy: 0.9982\n",
            "Epoch 62/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 63/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0738 - val_accuracy: 0.9982\n",
            "Epoch 64/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 65/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0755 - val_accuracy: 0.9982\n",
            "Epoch 66/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0756 - val_accuracy: 0.9982\n",
            "Epoch 67/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7552 - accuracy: 0.9983 - val_loss: 5.0753 - val_accuracy: 0.9982\n",
            "Epoch 68/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 69/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 70/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 71/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 72/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 73/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 74/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 75/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0754 - val_accuracy: 0.9982\n",
            "Epoch 76/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 77/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0749 - val_accuracy: 0.9982\n",
            "Epoch 78/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0745 - val_accuracy: 0.9982\n",
            "Epoch 79/150\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 80/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 81/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0751 - val_accuracy: 0.9982\n",
            "Epoch 82/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 83/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 84/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0737 - val_accuracy: 0.9982\n",
            "Epoch 85/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0744 - val_accuracy: 0.9982\n",
            "Epoch 86/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0755 - val_accuracy: 0.9982\n",
            "Epoch 87/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0753 - val_accuracy: 0.9982\n",
            "Epoch 88/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0748 - val_accuracy: 0.9982\n",
            "Epoch 89/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 90/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 91/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 92/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 93/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0737 - val_accuracy: 0.9982\n",
            "Epoch 94/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 95/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7538 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 96/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 97/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 98/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 99/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 100/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 101/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0754 - val_accuracy: 0.9982\n",
            "Epoch 102/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0763 - val_accuracy: 0.9982\n",
            "Epoch 103/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7550 - accuracy: 0.9983 - val_loss: 5.0753 - val_accuracy: 0.9982\n",
            "Epoch 104/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 105/150\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0749 - val_accuracy: 0.9982\n",
            "Epoch 106/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0749 - val_accuracy: 0.9982\n",
            "Epoch 107/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 108/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 109/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0737 - val_accuracy: 0.9982\n",
            "Epoch 110/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 111/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 112/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 113/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0738 - val_accuracy: 0.9982\n",
            "Epoch 114/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0736 - val_accuracy: 0.9982\n",
            "Epoch 115/150\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 3.7547 - accuracy: 0.9983 - val_loss: 5.0751 - val_accuracy: 0.9982\n",
            "Epoch 116/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7544 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 117/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 118/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 119/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 120/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 121/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 122/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7537 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 123/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 124/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 125/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0750 - val_accuracy: 0.9982\n",
            "Epoch 126/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7542 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 127/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7549 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 128/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7549 - accuracy: 0.9983 - val_loss: 5.0745 - val_accuracy: 0.9982\n",
            "Epoch 129/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 130/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7540 - accuracy: 0.9983 - val_loss: 5.0751 - val_accuracy: 0.9982\n",
            "Epoch 131/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n",
            "Epoch 132/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 133/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 134/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 135/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0735 - val_accuracy: 0.9982\n",
            "Epoch 136/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7543 - accuracy: 0.9983 - val_loss: 5.0773 - val_accuracy: 0.9982\n",
            "Epoch 137/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0739 - val_accuracy: 0.9982\n",
            "Epoch 138/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0746 - val_accuracy: 0.9982\n",
            "Epoch 139/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7545 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 140/150\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 141/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0740 - val_accuracy: 0.9982\n",
            "Epoch 142/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0737 - val_accuracy: 0.9982\n",
            "Epoch 143/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 144/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7536 - accuracy: 0.9983 - val_loss: 5.0743 - val_accuracy: 0.9982\n",
            "Epoch 145/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0742 - val_accuracy: 0.9982\n",
            "Epoch 146/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7541 - accuracy: 0.9983 - val_loss: 5.0741 - val_accuracy: 0.9982\n",
            "Epoch 147/150\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 3.7546 - accuracy: 0.9983 - val_loss: 5.0738 - val_accuracy: 0.9982\n",
            "Epoch 148/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0737 - val_accuracy: 0.9982\n",
            "Epoch 149/150\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0749 - val_accuracy: 0.9982\n",
            "Epoch 150/150\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 3.7539 - accuracy: 0.9983 - val_loss: 5.0747 - val_accuracy: 0.9982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "KDeQoy564yGq",
        "outputId": "ef915e77-73d6-479f-ada2-4d600a37e67b"
      },
      "source": [
        "plt.plot(history1.history1['accuracy'], label='train')\n",
        "plt.plot(history1.history1['val_accuracy'], label='target')\n",
        "plt.legend();"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWOOzFOS51cH"
      },
      "source": [
        "test1 = tf.stack(test1)\n",
        "target = tf.stack(target)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "3g36IrXj5DM6",
        "outputId": "19bfc26e-4f47-4e6b-f7bf-95c0c1d22392"
      },
      "source": [
        "history = NN_model.fit(np.array(test1),np.array(target), epochs=150, batch_size=50, validation_split = 0.2)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-7db8a9115cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1613\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2479\n  y sizes: 1956\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    }
  ]
}