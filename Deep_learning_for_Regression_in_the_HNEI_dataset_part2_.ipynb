{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning for Regression in the HNEI dataset part2 .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqKBdoHQtQhblU3gr+1nmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarekAzzouni/Baterries-ML-Lithium-Ions-01/blob/main/Deep_learning_for_Regression_in_the_HNEI_dataset_part2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dIK5D6OnJkw"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from scipy.stats import norm, boxcox\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import requests\n",
        "\n",
        "\n",
        "from warnings import simplefilter\n",
        "import warnings\n",
        "# ignore all warnings\n",
        "simplefilter(action='ignore')\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj07k0tAnmia"
      },
      "source": [
        "url=\"https://www.batteryarchive.org/data/HNEI_18650_NMC_LCO_25C_0-100_0.5-1.5C_a_timeseries.csv\"\n",
        "s = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(s.decode('utf-8')))"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "nftDhI71nqjY",
        "outputId": "05d921ef-80e4-4026-a83a-ef0513a7c5e9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_Time</th>\n",
              "      <th>Test_Time (s)</th>\n",
              "      <th>Cycle_Index</th>\n",
              "      <th>Current (A)</th>\n",
              "      <th>Voltage (V)</th>\n",
              "      <th>Charge_Capacity (Ah)</th>\n",
              "      <th>Discharge_Capacity (Ah)</th>\n",
              "      <th>Charge_Energy (Wh)</th>\n",
              "      <th>Discharge_Energy (Wh)</th>\n",
              "      <th>Environment_Temperature (C)</th>\n",
              "      <th>Cell_Temperature (C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-05-22 11:46:56</td>\n",
              "      <td>30.014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-05-22 11:47:26</td>\n",
              "      <td>59.999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-05-22 11:47:33</td>\n",
              "      <td>67.294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-05-22 11:47:41</td>\n",
              "      <td>74.303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-05-22 11:47:48</td>\n",
              "      <td>81.310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>3.659</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date_Time  ...  Cell_Temperature (C)\n",
              "0  2013-05-22 11:46:56  ...                   NaN\n",
              "1  2013-05-22 11:47:26  ...                   NaN\n",
              "2  2013-05-22 11:47:33  ...                   NaN\n",
              "3  2013-05-22 11:47:41  ...                   NaN\n",
              "4  2013-05-22 11:47:48  ...                   NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "E0RHHIo_nrj_",
        "outputId": "16829c09-957e-4d0a-b172-6e7f37482e61"
      },
      "source": [
        "train = df[df['Cycle_Index'] == 1 ]\n",
        "train"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_Time</th>\n",
              "      <th>Test_Time (s)</th>\n",
              "      <th>Cycle_Index</th>\n",
              "      <th>Current (A)</th>\n",
              "      <th>Voltage (V)</th>\n",
              "      <th>Charge_Capacity (Ah)</th>\n",
              "      <th>Discharge_Capacity (Ah)</th>\n",
              "      <th>Charge_Energy (Wh)</th>\n",
              "      <th>Discharge_Energy (Wh)</th>\n",
              "      <th>Environment_Temperature (C)</th>\n",
              "      <th>Cell_Temperature (C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-05-22 11:46:56</td>\n",
              "      <td>30.014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-05-22 11:47:26</td>\n",
              "      <td>59.999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-05-22 11:47:33</td>\n",
              "      <td>67.294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.670</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-05-22 11:47:41</td>\n",
              "      <td>74.303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.664</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-05-22 11:47:48</td>\n",
              "      <td>81.310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>3.659</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.025</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>2013-05-22 15:49:05</td>\n",
              "      <td>14558.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.342</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>2013-05-22 15:49:35</td>\n",
              "      <td>14588.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>2013-05-22 15:50:05</td>\n",
              "      <td>14618.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>2013-05-22 15:50:34</td>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>2013-05-22 15:50:35</td>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1956 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Date_Time  ...  Cell_Temperature (C)\n",
              "0     2013-05-22 11:46:56  ...                   NaN\n",
              "1     2013-05-22 11:47:26  ...                   NaN\n",
              "2     2013-05-22 11:47:33  ...                   NaN\n",
              "3     2013-05-22 11:47:41  ...                   NaN\n",
              "4     2013-05-22 11:47:48  ...                   NaN\n",
              "...                   ...  ...                   ...\n",
              "1951  2013-05-22 15:49:05  ...                   NaN\n",
              "1952  2013-05-22 15:49:35  ...                   NaN\n",
              "1953  2013-05-22 15:50:05  ...                   NaN\n",
              "1954  2013-05-22 15:50:34  ...                   NaN\n",
              "1955  2013-05-22 15:50:35  ...                   NaN\n",
              "\n",
              "[1956 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTEgGyLojcA"
      },
      "source": [
        "test = df[df['Cycle_Index'] == 2 ]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpm8-1MbovrH"
      },
      "source": [
        "def get_data():\n",
        "    #get train data\n",
        "    #train_data_path ='train.csv'\n",
        "    train = df[df['Cycle_Index'] == 1 ]\n",
        "    \n",
        "    #get test data\n",
        "    #test_data_path ='test.csv'\n",
        "    test = df[df['Cycle_Index'] == 2 ]\n",
        "    \n",
        "    return train , test\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-agIuTEpOPW"
      },
      "source": [
        "#rename the charge capacity\n",
        "train = train.rename(columns={'Charge_Capacity (Ah)': 'Charge_Capacity'})\n",
        "test = test.rename(columns={'Charge_Capacity (Ah)': 'Charge_Capacity'})"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPiIKpzptvef"
      },
      "source": [
        "train1 = train.drop(['Environment_Temperature (C)','Cell_Temperature (C)','Date_Time'],axis=1)\n",
        "test1 = test.drop(['Environment_Temperature (C)','Cell_Temperature (C)','Date_Time'],axis=1)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "JeThOGmUqvQm",
        "outputId": "6cec9af7-0c60-4f54-fde9-e970d48d2f14"
      },
      "source": [
        "train1"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test_Time (s)</th>\n",
              "      <th>Cycle_Index</th>\n",
              "      <th>Current (A)</th>\n",
              "      <th>Voltage (V)</th>\n",
              "      <th>Charge_Capacity</th>\n",
              "      <th>Discharge_Capacity (Ah)</th>\n",
              "      <th>Charge_Energy (Wh)</th>\n",
              "      <th>Discharge_Energy (Wh)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.779</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.670</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>74.303</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.398</td>\n",
              "      <td>3.664</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81.310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>3.659</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>14558.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.342</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>14588.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>14618.462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>14648.447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.341</td>\n",
              "      <td>2.869</td>\n",
              "      <td>0.000</td>\n",
              "      <td>11.58</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1956 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Test_Time (s)  Cycle_Index  ...  Charge_Energy (Wh)  Discharge_Energy (Wh)\n",
              "0            30.014          1.0  ...                0.00                  0.000\n",
              "1            59.999          1.0  ...                0.00                  0.000\n",
              "2            67.294          1.0  ...                0.00                  0.005\n",
              "3            74.303          1.0  ...                0.00                  0.015\n",
              "4            81.310          1.0  ...                0.00                  0.025\n",
              "...             ...          ...  ...                 ...                    ...\n",
              "1951      14558.462          1.0  ...               11.58                  0.000\n",
              "1952      14588.447          1.0  ...               11.58                  0.000\n",
              "1953      14618.462          1.0  ...               11.58                  0.000\n",
              "1954      14648.447          1.0  ...               11.58                  0.000\n",
              "1955      14648.447          1.0  ...               11.58                  0.000\n",
              "\n",
              "[1956 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJN20myzraZH"
      },
      "source": [
        "Col_target = [\"Charge_Capacity\"]\n",
        "target = train1[Col_target]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TICv9OhfsBuc",
        "outputId": "12f675c1-ff30-4346-ec5a-c126032b0e6c"
      },
      "source": [
        "train1.columns"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Test_Time (s)', 'Cycle_Index', 'Current (A)', 'Voltage (V)',\n",
              "       'Charge_Capacity', 'Discharge_Capacity (Ah)', 'Charge_Energy (Wh)',\n",
              "       'Discharge_Energy (Wh)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H6CruFnpPm_"
      },
      "source": [
        "\n",
        "\n",
        "def get_combined_data():\n",
        "  #reading train data\n",
        "  train1 , test1 = get_data()\n",
        "  #train.drop(['Charge_Capacity'],axis = 1 , inplace = True)\n",
        "\n",
        "  combined = train1.append(test)\n",
        "  combined.reset_index(inplace=True)\n",
        "  combined.drop(['Environment_Temperature (C)', 'Cell_Temperature (C)'], inplace=True, axis=1)\n",
        "  return combined, target\n",
        "\n",
        "#Load train and test data into pandas DataFrames\n",
        "train_data, test_data = get_data()\n",
        "\n",
        "#Combine train and test data to process them together\n",
        "combined, target = get_combined_data()"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmeEOBqHpRUX",
        "outputId": "27f7800f-80ae-4050-fcd9-b5d2bc8f57f2"
      },
      "source": [
        "combined.info()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4559 entries, 0 to 4558\n",
            "Data columns (total 11 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   index                    4559 non-null   int64  \n",
            " 1   Date_Time                4559 non-null   object \n",
            " 2   Test_Time (s)            4559 non-null   float64\n",
            " 3   Cycle_Index              4559 non-null   float64\n",
            " 4   Current (A)              4559 non-null   float64\n",
            " 5   Voltage (V)              4559 non-null   float64\n",
            " 6   Charge_Capacity (Ah)     1956 non-null   float64\n",
            " 7   Discharge_Capacity (Ah)  4559 non-null   float64\n",
            " 8   Charge_Energy (Wh)       4559 non-null   float64\n",
            " 9   Discharge_Energy (Wh)    4559 non-null   float64\n",
            " 10  Charge_Capacity          2603 non-null   float64\n",
            "dtypes: float64(9), int64(1), object(1)\n",
            "memory usage: 391.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zImZPaj8slgp"
      },
      "source": [
        "def get_cols_with_no_nans(df1,col_type):\n",
        "    '''\n",
        "    Arguments :\n",
        "    df : The dataframe to process\n",
        "    col_type : \n",
        "          num : to only get numerical columns with no nans\n",
        "          no_num : to only get nun-numerical columns with no nans\n",
        "          all : to get any columns with no nans    \n",
        "    '''\n",
        "    if (col_type == 'num'):\n",
        "        predictors = df1.select_dtypes(exclude=['object'])\n",
        "    elif (col_type == 'no_num'):\n",
        "        predictors = df1.select_dtypes(include=['object'])\n",
        "    elif (col_type == 'all'):\n",
        "        predictors = df1\n",
        "    else :\n",
        "        print('Error : choose a type (num, no_num, all)')\n",
        "        return 0\n",
        "    cols_with_no_nans = []\n",
        "    for col in predictors.columns:\n",
        "        if not df1[col].isnull().any():\n",
        "            cols_with_no_nans.append(col)\n",
        "    return cols_with_no_nans"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_GRCn_Isqdq"
      },
      "source": [
        "num_cols = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols = get_cols_with_no_nans(combined , 'no_num')"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCgvle8sss1S",
        "outputId": "1015d3f3-fc2c-4604-9735-f742f6843e21"
      },
      "source": [
        "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 8\n",
            "Number of nun-numerical columns with no nan values : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "HVzXcA5cucZF",
        "outputId": "5474cce3-74a3-4c0f-dc01-06324756332c"
      },
      "source": [
        "combined = combined[num_cols + cat_cols]\n",
        "combined.hist(figsize = (12,10))\n",
        "plt.show()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izNJlhdgvtBG"
      },
      "source": [
        "***One Hot Encode The Categorical Features :***\n",
        "\n",
        "We will encode the categorical features using one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF6W9tJ9vqOq"
      },
      "source": [
        "def oneHotEncode(df1,colNames):\n",
        "    for col in colNames:\n",
        "        if( df1[col].dtype == np.dtype('object')):\n",
        "            dummies = pd.get_dummies(df1[col],prefix=col)\n",
        "            df1 = pd.concat([df1,dummies],axis=1)\n",
        "\n",
        "            #drop the encoded column\n",
        "            df1.drop([col],axis = 1 , inplace=True)\n",
        "    return df1"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwwNWDrmv3rT",
        "outputId": "f6129229-8701-4e16-a65f-a6f6bbacce57"
      },
      "source": [
        "print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\n",
        "combined = oneHotEncode(combined, cat_cols)\n",
        "print('There are {} columns after encoding categorical features'.format(combined.shape[1]))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were 9 columns before encoding categorical features\n",
            "There are 4566 columns after encoding categorical features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKxhl4zOv73i"
      },
      "source": [
        "Now, split back combined dataFrame to training data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqjnlzWLv8nN"
      },
      "source": [
        "def split_combined():\n",
        "    global combined\n",
        "    train = combined[:1460]\n",
        "    test = combined[1460:]\n",
        "\n",
        "    return train , test "
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHZOKq09wAF6"
      },
      "source": [
        "train, test = split_combined()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZJup4fQwEIp"
      },
      "source": [
        "# Second : Make the Deep Neural Network\n",
        "\n",
        "\n",
        "*   Define a sequential model\n",
        "*   Add some dense layers\n",
        "*   Use 'relu' as the activation function in the hidden layers\n",
        "*   Use a 'normal' initializer as the kernal_intializer\n",
        "\n",
        "```\n",
        " Initializers define the way to set the initial random weights of Keras layers.\n",
        "```\n",
        "*   We will use mean_absolute_error as a loss function\n",
        "*   Define the output layer with only one node\n",
        "*   Use 'linear 'as the activation function for the output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzeYnOEiwlIE"
      },
      "source": [
        "NN_model = Sequential()"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0am5f-ExNvB"
      },
      "source": [
        "**The input Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6uA15abxQeV"
      },
      "source": [
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD-iAszBxSSc"
      },
      "source": [
        "**The Hidden Layers**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78s9O0_LxUmL"
      },
      "source": [
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgubWleQxbOW"
      },
      "source": [
        "**The output layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Ukeeirxffa"
      },
      "source": [
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLFK8K6Kxjwu"
      },
      "source": [
        "**Compile the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K37ClO-rxlWS",
        "outputId": "900479cc-39eb-444a-a484-b20dd05bc9ac"
      },
      "source": [
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               584576    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 749,441\n",
            "Trainable params: 749,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNsgJNQnxsIP"
      },
      "source": [
        "**Define a checkpoint callback**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867yMmqvxwVc"
      },
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJ39A_Rx2Hz"
      },
      "source": [
        "## Third : Train the model :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGR3u19Tx1hF",
        "outputId": "54e6f9d8-7f7e-450d-9959-48462a341523"
      },
      "source": [
        "NN_model.fit(train, target, epochs=100, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03467, saving model to Weights-001--0.03467.hdf5\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.03467\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0397 - val_mean_absolute_error: 0.0397\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.03467\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0236 - val_mean_absolute_error: 0.0236\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03467 to 0.02356, saving model to Weights-004--0.02356.hdf5\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02356 to 0.01550, saving model to Weights-005--0.01550.hdf5\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0501 - val_mean_absolute_error: 0.0501\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01550\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01550\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01550 to 0.01501, saving model to Weights-008--0.01501.hdf5\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01501\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01501\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0610 - val_mean_absolute_error: 0.0610\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01501\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01501\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01501\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01501\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0224 - mean_absolute_error: 0.0224 - val_loss: 0.0471 - val_mean_absolute_error: 0.0471\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01501\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01501\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0328 - val_mean_absolute_error: 0.0328\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01501\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0334 - val_mean_absolute_error: 0.0334\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01501\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0838 - val_mean_absolute_error: 0.0838\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01501\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01501 to 0.01241, saving model to Weights-020--0.01241.hdf5\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0368 - val_mean_absolute_error: 0.0368\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01241\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01241\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01241\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01241\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0192 - val_mean_absolute_error: 0.0192\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01241\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0634 - val_mean_absolute_error: 0.0634\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01241\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0233 - mean_absolute_error: 0.0233 - val_loss: 0.0922 - val_mean_absolute_error: 0.0922\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01241\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0336 - val_mean_absolute_error: 0.0336\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01241\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0738 - val_mean_absolute_error: 0.0738\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01241\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0798 - val_mean_absolute_error: 0.0798\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01241\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01241\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01241\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0513 - val_mean_absolute_error: 0.0513\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01241\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01241\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0474 - val_mean_absolute_error: 0.0474\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01241\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01241\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01241\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0396 - val_mean_absolute_error: 0.0396\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01241\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01241\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01241\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01241\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0509 - val_mean_absolute_error: 0.0509\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01241\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0230 - val_mean_absolute_error: 0.0230\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01241\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01241\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0434 - val_mean_absolute_error: 0.0434\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01241\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01241\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0178 - val_mean_absolute_error: 0.0178\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01241\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01241\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01241\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0555 - val_mean_absolute_error: 0.0555\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01241\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0542 - val_mean_absolute_error: 0.0542\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.01241\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.01241 to 0.01219, saving model to Weights-052--0.01219.hdf5\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0626 - val_mean_absolute_error: 0.0626\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.01219\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0129 - mean_absolute_error: 0.0129 - val_loss: 0.0385 - val_mean_absolute_error: 0.0385\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.01219\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.01219\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.01219\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.01219\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0430 - val_mean_absolute_error: 0.0430\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.01219\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.01219\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.01219\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0391 - val_mean_absolute_error: 0.0391\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.01219\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0155 - mean_absolute_error: 0.0155 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.01219\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.01219\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0485 - val_mean_absolute_error: 0.0485\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.01219\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0280 - mean_absolute_error: 0.0280 - val_loss: 0.0340 - val_mean_absolute_error: 0.0340\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.01219\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.01219\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0475 - val_mean_absolute_error: 0.0475\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.01219\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.01219\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.01219\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.01219\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.01219\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.01219\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0635 - val_mean_absolute_error: 0.0635\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.01219\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0236 - mean_absolute_error: 0.0236 - val_loss: 0.1206 - val_mean_absolute_error: 0.1206\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.01219\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0464 - val_mean_absolute_error: 0.0464\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.01219\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.01219\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0260 - mean_absolute_error: 0.0260 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.01219\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0314 - val_mean_absolute_error: 0.0314\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.01219\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.01219\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0480 - val_mean_absolute_error: 0.0480\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.01219\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0275 - val_mean_absolute_error: 0.0275\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.01219\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.01219\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.01219\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0334 - val_mean_absolute_error: 0.0334\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.01219\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0206 - mean_absolute_error: 0.0206 - val_loss: 0.0657 - val_mean_absolute_error: 0.0657\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.01219\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.01219\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0440 - val_mean_absolute_error: 0.0440\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.01219\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.01219\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0133 - mean_absolute_error: 0.0133 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.01219\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.01219\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.01219\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0157 - mean_absolute_error: 0.0157 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.01219\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.01219\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0142 - val_mean_absolute_error: 0.0142\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.01219\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.01219\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0411 - val_mean_absolute_error: 0.0411\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.01219\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0628 - val_mean_absolute_error: 0.0628\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.01219\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.01219\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0342 - val_mean_absolute_error: 0.0342\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.01219\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.01219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73b9fb8a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "dQi8BwqvzGAk",
        "outputId": "ccc1d1db-539b-462a-c608-b25c0c5f1878"
      },
      "source": [
        "# Load wights file of the best model :\n",
        "wights_file = 'Weights-478--18738.19831.hdf5' # choose the best checkpoint \n",
        "NN_model.load_weights(wights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-d1d263513391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load wights file of the best model :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Weights-478--18738.19831.hdf5'\u001b[0m \u001b[0;31m# choose the best checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwights_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2292\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'Weights-478--18738.19831.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    }
  ]
}